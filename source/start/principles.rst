.. _principles:

Understand the Developer Cloud Sandbox key principles
=====================================================

The Sandbox filesystems
^^^^^^^^^^^^^^^^^^^^^^^

In the context of the application life-cycle, the Sandbox has three filesystems (or directories):

* /home/<user> that we refer to as *HOME* 
* /application that we refer to as *APPLICATION*
* /share that we refer to as *SHARE*

HOME filesystem
"""""""""""""""

A user's home directory is intended to contain that user's files; including text documents, music, pictures or videos, etc. It may also include their configuration files of preferred settings for any software they have used there and might have tailored to their liking: web browser bookmarks, favorite desktop wallpaper and themes, passwords to any external services accessed via a given software, etc. The user can install executable software in this directory, but it will only be available to users with permission to this directory. The home directory can be organized further with the use of sub-directories.

As such, the *HOME* is used to store the user's files. It can be used to store source files (the compiled programs would then go *APPLICATION*). 

.. NOTE:: At job or workflow execution time, the Sandbox uses a system user to execute the application. This system user cannot read files in *HOME*.  
  When the application is run on the Sandbox Runtime Environment, the *HOME* directory is not available in any of the computing nodes. 

APPLICATION filesystem
""""""""""""""""""""""

The *APPLICATION* filesystem contains all the files required to run the application.

The *APPLICATION* filesystem is available on the Sandbox as /application.

.. NOTE:: Whenever an application wrapper script needs to use the *APPLICATION* value (/application) the variable $_CIOP_APPLICATION_PATH, example:

.. code-block:: bash
  export BEAM_HOME=$_CIOP_APPLICATION_PATH/common/beam-4.11


The *APPLICATION* contains

* the Application Descriptor File, named _application.xml_ 
* a folder for each job template

.. seealso:: The Application Descriptor file is described in :doc:`/reference/application`

A *job template* folder contains:

* the streaming executable script, a script in your prefered language (e.g. bash, R or Python) that deals with the *stdin* managed by the Sandbox (e.g. EO data URLs to be passed to ciop-copy). 

There isn't a defined naming convention although it is often called *run* with an extension:

* run.sh for bash scripting streaming executable
* run.R for R streaming executable
* run.py for python streaming executable

.. NOTE:: The streaming executable script will read its inputs via stdin managed by the Hadoop Map Reduce streaming underlying layer 

* a set of folders such as:

  * /application/<job template name>/bin standing for "binaries" and contains certain fundamental job utilities which are in part needed by the job wrapper script.
  * /application/<job template name>/etc containing job-wide configuration files
  * /application/<job template name>/lib containing the job libraries
  * ...

.. NOTE:: There aren't any particular rules for the folders in the job template folder

The *APPLICATION* of a workflow with two jobs can then be represented as

.. code-block:: bash

  /application/
    application.xml
    /job_template_1
      run.sh
      /bin
      /etc
    /job_template_2
      run.sh
      /bin
      /lib

SHARE filesystem
""""""""""""""""

The *SHARE* filesystem is the Linux mount point for the Hadoop Distributed File System (HDFS). 

The HDFS filesystem is used to store the application's job outputs, generated by the execution of ciop-simjob and/or ciop-simwf.

The *SHARE* filesystem is available on the Sandbox as /share, and the HDFS distributed filesystem access point is /tmp thus, on the Sandbox, /share/tmp is the root of the distributed filesysyem.

.. WARNING:: In Cluster mode (production environment), the *SHARE* mount is no longuer available. Do not use /share to reference files avaialable on HDFS, but rather use the hdfs:// path returned by the ciop-publish utility.

For example, you can access a data folder with Job outputs either through:

.. code-block:: bash

  $ ls /share/tmp/sandbox/beam_arithm/node_expression/data 

or

.. code-block:: bash

  $ hadoop dfs -ls /tmp/sandbox/beam_arithm/node_expression/data (without /share)


**SHARE for ciop-simjob**

When the ciop-simjob is invoked to run a node of the workflow, the outputs are found in:

.. code-block:: bash

  /share/tmp/sandbox/<workflow name>/<node name>
 
and with the hdfs:// URL:

.. code-block:: bash

  hdfs://<name_node>/tmp/sandbox/<workflow name>/<node name>

A job can be executed several times, but the results of a previous execution will be overwritten.

.. TIP:: the workflow and its node names are defined in the Application Descriptor File

.. TIP:: ciop-simjob -n will list the workflow node name(s), check the ciop-simjob reference page here: :doc:`/reference/man/ciop-simjob`

**SHARE for ciop-simwf**

When the ciop-simwf is invoked to run the complete application workflow, the outputs are found in a dedicated folder under *SHARE*:

.. code-block:: bash

  /share/tmp/sandbox/run/<run identifier>/<node name>
 
and with the hdfs:// URL:

.. code-block:: bash

  hdfs://<name_node>/tmp/sandbox/run/<run identifier>/<node name>
  
Unlike to ciop-simjob, ciop-simwf is keeping track of all its workflow execution runs. 

This feature allows to compare the results from different sets of parameters for example.

.. TIP:: check the Application descriptor XML file defines the default parameter values and how to override these in the workflow

The Application Workflow
^^^^^^^^^^^^^^^^^^^^^^^^

Role of the Directed Acyclic Graph (DAG)
""""""""""""""""""""""""""""""""""""""""

The DAG helps you to sequence your Application workflow with simple rules. For the Hadoop Map/Reduce programming framework, a workflow is subject to constraints that certain tasks must be performed earlier than others. 

The Nodes of the DAG can be Mappers, Reducers or (starting from ciop v1.2) Map/Reduce Hadoop jobs.

Mappers: if the Node type is a Mapper, the number of tasks is defined by the number of available slots on the cluster.

Reducers: if the Node type is a Reducer, the number of task is fixed to 1, independently from the cluster dimension.

Map/Reduce: if the Node type is Map/Reduce, each parallel task is re-arranging its task outputs according to the program implementing the Reducer.

Hadoop Streaming
""""""""""""""""

Hadoop will split (distribute) the standard input to each task created on the cluster from a Job template.

The input split depends on the number of available task slots. 

The number of task slots depends on the cluster dimension. 

In the Developer Cloud Sandbox environment (pseudo-cluster mode), the cluster dimension is 1 and the number of the available task slots is 2 (running on a 2-Cores CPU).

In the IaaS Production environment (cluster mode), the cluster dimension is n (the servers provisioned on the cluster) and the number of available tasks slots is n x m (m-Cores CPU of the provisioned server type).

The Application Descriptor file
"""""""""""""""""""""""""""""""

The application descriptor file contains the definition of the application in terms of:

    job templates including:
        streaming executable
        default parameters
        job default configuration
    workflow including the workflow nodes defined with
        the source for the inputs (e.g. a previous node, a catalogue series, a local file)
        their parameter values to override the default parameters (defined in the job template above)

Type

The application descriptor is an XML file available in $_CIOP_APPLICATION_PATH/application.xml

    Note: the value $_CIOP_APPLICATION_PATH is /application

Format

The application descriptor file structure is available below:


+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
| Level	    | Tag name              | Descendants                                               | Tag Contents                  | Cardinality   | Attribute name                | Attribute value    |
+===========+=======================+===========================================================+===============================+===============+===============================+====================+
|>          | application           | All                                                       | -                             | 1..1          | -                             | -                  |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|1          | jobTemplates          | jobTemplate                                               | -                             | 1..1          | -                             | -                  |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|2          | jobTemplate           | streamingExecutable, defaultParameters, defaultJobconf    | -                             | 1..*          | id                            |job template name   |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+
|3          | streamingExecutable   | none                                                      | path to streaming executable	| 1..1          | -                             | -                  |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|3          | defaultParameters     | parameter                                                 | -                             | 0..1          | -                             | -                  |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|4          | parameter             | -                                                         | parameter default value       | 0..*          | id                            |parameter name      |	
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|3          | defaultJobconf        | -                                                         | -                             | 0..1          | -                             | -                  |		
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|4          | property              | -                                                         | property value                | 0..*          | id                            | property value     |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|1          | workflow              | workflowVersion,node                                      | -                             | 1..1          | id                            | workflow name      |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|2          | workflowVersion       | -                                                         | workflow version              | 1..1          | -                             | -                  |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|2          | node                  | job, sources, parameters                                  | -                             | 1..*          | id                            | node name	     |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|3          | job                   | -                                                         | -                             | 1..1          | id                            |job template name   |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|3          | sources               | source                                                    | -                             | 1..1          | -                             | -                  |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|4          | source                | -                                                         | source value                  | 1..*          | refid                         |file:urls, wf:node, |
|           |                       |                                                           |                               |               |                               |cas:series, str:list|
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|3          | parameters            | parameter                                                 | -                             | 0..*          | -                             | -                  |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	
|4          | parameter             | -                                                         | parameter value (overrides    | 0..*          | id                            | parameter name     |
|           |                       |                                                           |  the default value)		|               |                               |                    |
+-----------+-----------------------+-----------------------------------------------------------+-------------------------------+---------------+-------------------------------+--------------------+	


.. tip:: Check that your application descriptor file is well formed with the :doc:`ciop-appcheck </reference/man/ciop-appcheck>` utility

